{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191ae9bf",
   "metadata": {},
   "source": [
    "# Local OpenAI API Demo (CPU)\n",
    "\n",
    "This notebook mirrors the original Kaggle prototype, but everything runs on a local CPU-only machine. You will:\n",
    "\n",
    "1. Install dependencies.\n",
    "2. Download a tiny Hugging Face model.\n",
    "3. Launch the OpenAI-compatible Flask server from `scripts/server.py`.\n",
    "4. (Optional) Expose the API through ngrok.\n",
    "5. Send chat completion requests just like the original workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8319ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "MODEL_REPO = os.getenv(\"MODEL_REPO\", \"sshleifer/tiny-gpt2\")\n",
    "MODEL_CACHE_DIR = Path(os.getenv(\"MODEL_CACHE_DIR\", Path(\"models\") / MODEL_REPO.replace(\"/\", \"_\")))\n",
    "MODEL_CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "if hf_token:\n",
    "    print(\"Authenticating with Hugging Face token...\")\n",
    "    login(token=hf_token)\n",
    "else:\n",
    "    print(\"No HF_TOKEN found. Proceeding without authentication.\")\n",
    "\n",
    "print(f\"Using model repo: {MODEL_REPO}\")\n",
    "print(f\"Model cache dir: {MODEL_CACHE_DIR}\")\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=MODEL_REPO,\n",
    "    local_dir=str(MODEL_CACHE_DIR),\n",
    "    local_dir_use_symlinks=False,\n",
    "    token=hf_token,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1811b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "SERVER_LOG = Path(\"server.log\")\n",
    "PORT = int(os.getenv(\"PORT\", \"8000\"))\n",
    "BASE_URL = f\"http://127.0.0.1:{PORT}\"\n",
    "\n",
    "if 'SERVER_PROC' in globals():\n",
    "    print(\"Server already running.\")\n",
    "else:\n",
    "    env = os.environ.copy()\n",
    "    env[\"MODEL_REPO\"] = MODEL_REPO\n",
    "    env[\"MODEL_CACHE_DIR\"] = str(MODEL_CACHE_DIR)\n",
    "    env[\"PORT\"] = str(PORT)\n",
    "    SERVER_PROC = subprocess.Popen(\n",
    "        [sys.executable, \"scripts/server.py\"],\n",
    "        env=env,\n",
    "        stdout=SERVER_LOG.open(\"w\"),\n",
    "        stderr=subprocess.STDOUT,\n",
    "    )\n",
    "    print(f\"Started server (pid={SERVER_PROC.pid}). Logs -> {SERVER_LOG}\")\n",
    "\n",
    "for attempt in range(60):\n",
    "    try:\n",
    "        resp = requests.get(f\"{BASE_URL}/health\", timeout=2)\n",
    "        if resp.status_code == 200:\n",
    "            print(\"‚úÖ Server is up!\")\n",
    "            break\n",
    "    except requests.RequestException:\n",
    "        pass\n",
    "    time.sleep(1)\n",
    "else:\n",
    "    raise RuntimeError(\"Server did not become ready. Check server.log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyngrok import ngrok\n",
    "\n",
    "public_url = BASE_URL\n",
    "\n",
    "authtoken = os.getenv(\"NGROK_AUTHTOKEN\")\n",
    "if authtoken:\n",
    "    ngrok.set_auth_token(authtoken)\n",
    "    tunnel = ngrok.connect(PORT, \"http\")\n",
    "    public_url = tunnel.public_url\n",
    "    print(\"üöÄ Public URL:\", public_url)\n",
    "else:\n",
    "    print(\"Ngrok token not set. Using local endpoint only.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "\n",
    "api_base = public_url.rstrip(\"/\") + \"/v1\"\n",
    "client = OpenAI(base_url=api_base, api_key=os.getenv(\"OPENAI_API_KEY\", \"local-demo\"))\n",
    "\n",
    "models = client.models.list().data\n",
    "if not models:\n",
    "    raise RuntimeError(\"No models registered\")\n",
    "model_id = models[0].id\n",
    "print(\"Using model:\", model_id)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself in one short sentence.\"},\n",
    "]\n",
    "\n",
    "start = time.perf_counter()\n",
    "completion = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=messages,\n",
    "    max_tokens=80,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    ")\n",
    "print(\"‚è±Ô∏è Total time:\", time.perf_counter() - start)\n",
    "print(\"\n",
    "--- Answer ---\")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3fc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "security_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You offer payload obfuscation ideas for authorized pentests.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Given the payload {cat${IFS}/etc/passwd} and CVE-1999-1556, \"\n",
    "            \"produce a JSON array with three obfuscated variants.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "security_resp = client.chat.completions.create(\n",
    "    model=model_id,\n",
    "    messages=security_messages,\n",
    "    temperature=0.2,\n",
    "    max_tokens=120,\n",
    "    top_p=0.7,\n",
    ")\n",
    "print(\"--- Security Output ---\")\n",
    "print(security_resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e4afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"API base:\", api_base)\n",
    "print(\"Model id:\", model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26442dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the server when you finish experimenting\n",
    "if 'SERVER_PROC' in globals():\n",
    "    SERVER_PROC.terminate()\n",
    "    SERVER_PROC.wait(timeout=10)\n",
    "    del SERVER_PROC\n",
    "    print(\"Server stopped.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
